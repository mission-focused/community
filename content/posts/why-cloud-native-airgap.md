---
title: 'Why Cloud Native Needs to Work Offline'
date: '2025-04-11T13:00:00Z' #6am PT
# weight: 1
# aliases: ["/first"]
tags: ["Airgap", "Cloud-Native"]
author: "Brandt Keller"
# author: ["Me", "You"] # multiple authors
showToc: true
TocOpen: false
draft: false
hidemeta: false
comments: false
description: "Why we need to be desigining cloud native applications to operate offline"
canonicalURL: "https://missionfocused.dev/posts/why-cloud-native-airgap"
disableHLJS: true # to disable highlightjs
disableShare: false
disableHLJS: false
hideSummary: false
searchHidden: true
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: true
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://content.bekindchooseviolence.com/cloud-native-offline.png" # image path/url
    alt: "<alt text>" # alt text
    caption: "<text>" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: true # only hide on current single page
editPost:
    URL: "https://github.com/mission-focused/community/content"
    Text: "Suggest Changes" # edit text
    appendFilePath: true # to append file path to Edit link
---

Welcome to the first post in my _Cloud Native Airgap Fundamentals_ series. 

If you’re reading this, odds are you’ve been burned by a dependency you didn’t even know you had.

A Helm chart that fetched something from an external source or had sub-charts.
A Kubernetes deployment that pulled an image at runtime. (IE Operator)
A pipeline that silently relied on a cloud API to fetch secrets.
A security application that requires centralized data retrieval for operation.

It works until it doesn’t. And when it *really* matters, that’s not good enough.

## Build like you won’t have connectivity

If you’ve ever tried to do a live demo over conference WiFi, you probably already understand.

It happens all the time:
- Live image pulls that timed out
- DNS failures in hotel networks
- Monitoring dashboards that refused to load
- Git-based automation that silently failed because of token expirations

But here’s the thing: this isn’t just about conference networks.

It’s about **airgapped systems**, **forward operating bases**, **spacecraft**, and **critical infrastructure**.  
It’s about **systems that have to work**, even when they’re **disconnected by design**.

## These environments aren’t edge cases

Disconnected environments aren’t just a curiosity. They’re operational requirements in:
- Defense and national security
- Regulated financial or health systems
- Remote scientific operations
- Space-based systems
- Industrial infrastructure with hard safety cutouts
- IoT and edge systems with minimal connectivity

The software still needs to work. The difference? You don’t get to “just pull that image again” or “re-run the deploy.”

There’s no “try again with better bandwidth.”

## What breaks when you're offline?

Let’s be clear - a lot of cloud native tooling assumes connectivity.

Here’s what typically falls apart:
- Image pulls from a centralized Registry
- Helm charts hosted in GitHub repos
- Terraform modules that live upstream
- Vault lookups to external KMS
- SaaS-based monitoring
- GitOps systems that need GitHub/GitLab to be reachable
- OAuth tokens or cloud identity integrations

You don’t have to be deploying to a submarine to hit these issues. I’ve seen them fail in *perfectly good environments* when someone misconfigured a proxy or other network setting.

## What if we designed like disconnection was the default?

When we treat disconnection as a design constraint, we’re forced to ask better questions:

- Does this app *need* to fetch anything at runtime?
- Can we bundle everything it needs: images, data, charts, policies?
- Can it degrade gracefully if connectivity drops mid-deploy?
- Does our automation work without external dependencies?

Here’s the thing: designing for disconnection makes **every system more resilient** - even the connected ones.

## Reframing cloud native

Let’s break it down.

| Traditional Cloud Native     | Disconnected-Aware Design            |
|-----------------------------|--------------------------------------|
| Always pull from remote     | Mirror or bundle all dependencies    |
| SaaS everything             | Self-host core telemetry/logs        |
| CI/CD assumes connectivity  | CI builds, CD works offline          |
| Runtime fetches             | Immutable and reproducible builds    |
| GitOps assumes GitHub       | Local Git or Git mirroring           |

This isn’t regression. It’s maturity.  
You still get GitOps, observability, containerization — just without the **fragile, implicit coupling to the cloud**.

## You don’t have to be airgapped to benefit

One of the best things about building like this is that it helps **everyone**:

- Fewer moving parts = faster MTTR
- Bundled deployments = repeatable outcomes
- Offline docs = teams aren’t blocked when things go sideways
- Self-contained monitoring = fewer blind spots

It doesn’t matter if you *can* connect - what matters is that you don’t **have to**.

## Summary

> Designing for disconnection makes your systems more resilient - even when the internet is available.

If your deployment depends on a live internet connection, it’s a liability.  
If your CI pipeline can’t produce a standalone artifact, it’s fragile.  
If your observability stack disappears when your VPN flakes - you’ve got a problem.

So ask yourself:
- Can I deploy this without connectivity?
- Can I debug it without SaaS dashboards?
- Can I prove it works offline?

If not - maybe it’s time to build like you’re airgapped.
Not because you are, but because **one day you might be**.

---

Want to learn more?
- Check out the [Zarf project](https://github.com/zarf-dev/zarf)
- Join us in the Kubernetes Slack in `#zarf`
- Or reach out on social—always happy to jam on disconnected infra